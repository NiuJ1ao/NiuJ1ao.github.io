<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IC DoC | Yuchen Niu</title>
    <link>https://example.com/tag/ic-doc/</link>
      <atom:link href="https://example.com/tag/ic-doc/index.xml" rel="self" type="application/rss+xml" />
    <description>IC DoC</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 06 May 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hue3a655598c6865a5273e9cfb01f02a1f_2400_512x512_fill_lanczos_center_3.png</url>
      <title>IC DoC</title>
      <link>https://example.com/tag/ic-doc/</link>
    </image>
    
    <item>
      <title>Calibrating Uncertainty Estimates for Machine Learning Models</title>
      <link>https://example.com/project/iso/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/iso/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;http://yingzhenli.net/home/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Yingzhen Li&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recent advances in machine learning have dramatically improved the ability of neural
networks to solve real-world problems. Machine learning methods are also more frequently
deployed in critical scenarios. This requires that machine learning models need to be both
accurate and reliable. So, calibrating a model to create a rigorous confidence set or estimates
that represent the actual correctness likelihood is essential. In this report, we review the
theoretical and practical concepts of uncertainty estimation and calibration. The history of
popular calibration models and their application are also covered, which will help understand
concepts more intuitively. We conduct experiments on the uncertainty estimation of neural
networks before and after applying various post-processing calibration methods. Empirical
results show that modern neural networks are often overconfident and poorly calibrated.
Temperature scaling is straightforward and surprisingly efficient at calibrating confidence for
classification models. Conformal prediction is a non-parametric distribution-free calibration
method for regression models. However, we notice that distribution shifts and biases can
easily influence the confidence interval for predictions from conformal inference. Ensembling
can be an implicit calibration method that can mitigate the overconfidence of neural networks
and provide stable predictions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt Tuning for Condescending Detection</title>
      <link>https://example.com/project/icnlp/</link>
      <pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/icnlp/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
