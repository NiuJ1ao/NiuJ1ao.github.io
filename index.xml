<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yuchen Niu</title>
    <link>https://example.com/</link>
      <atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" />
    <description>Yuchen Niu</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 31 Aug 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hue3a655598c6865a5273e9cfb01f02a1f_2400_512x512_fill_lanczos_center_3.png</url>
      <title>Yuchen Niu</title>
      <link>https://example.com/</link>
    </image>
    
    <item>
      <title>Data Augmentation in Infinitely Wide Neural Networks.</title>
      <link>https://example.com/project/master_thesis/</link>
      <pubDate>Wed, 31 Aug 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/master_thesis/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;https://mvdw.uk/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Mark van der Wilk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Infinitely wide neural networks have shown equivalence to Gaussian processes (GPs).This equivalence enables exact Bayesian inference for the posterior and predictivedistribution without ever instantiating a neural network, but by evaluating the corresponding GP. A major advantage of GPs over neural networks is that the hyperparameters can be optimised by backpropagation to maximise the marginal likelihood. However, the evaluation of the marginal likelihood is computationally intractable in large scale machine learning, especially when the training data is enlarged for better generalisation by generating a broader set of augmentations. In this project, we address the intractability by sparse Gaussian process regression and choose the bestmodel by maximising a variational lower bound of the true log marginal likelihood. We find that the sparse approximation estimates the true posterior on a regressiontask with few inducing points. However, it shows the difficulty of approximation on classification tasks. A comparison of the efficiency of different methods for selecting inducing points is also conducted. Furthermore, we study the invariances in the data and incorporate them into the model by summing over orbits. Empirical results show that the invariances can be learned in a supervised manner and demonstrate different characteristics from the infinitely wide neural networks.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Calibrating Uncertainty Estimates for Machine Learning Models</title>
      <link>https://example.com/project/iso/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/iso/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;http://yingzhenli.net/home/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Yingzhen Li&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recent advances in machine learning have dramatically improved the ability of neural
networks to solve real-world problems. Machine learning methods are also more frequently
deployed in critical scenarios. This requires that machine learning models need to be both
accurate and reliable. So, calibrating a model to create a rigorous confidence set or estimates
that represent the actual correctness likelihood is essential. In this report, we review the
theoretical and practical concepts of uncertainty estimation and calibration. The history of
popular calibration models and their application are also covered, which will help understand
concepts more intuitively. We conduct experiments on the uncertainty estimation of neural
networks before and after applying various post-processing calibration methods. Empirical
results show that modern neural networks are often overconfident and poorly calibrated.
Temperature scaling is straightforward and surprisingly efficient at calibrating confidence for
classification models. Conformal prediction is a non-parametric distribution-free calibration
method for regression models. However, we notice that distribution shifts and biases can
easily influence the confidence interval for predictions from conformal inference. Ensembling
can be an implicit calibration method that can mitigate the overconfidence of neural networks
and provide stable predictions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt Tuning for Condescending Detection</title>
      <link>https://example.com/project/icnlp/</link>
      <pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/icnlp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Exploring Generalization Ability of Pretrained Language Models on Arithmetic and Logical Reasoning</title>
      <link>https://example.com/publication/plm_arithmetic_logic/</link>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/publication/plm_arithmetic_logic/</guid>
      <description>&lt;!-- &lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;


&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;


Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --&gt;
</description>
    </item>
    
    <item>
      <title>Performance Characterization of Serverless Computing</title>
      <link>https://example.com/project/ug_thesis/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/ug_thesis/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;https://homepages.inf.ed.ac.uk/bgrot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Boris Grot&lt;/a&gt; and &lt;a href=&#34;https://homepages.inf.ed.ac.uk/s1373190/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Dmitrii Ustiugov&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Serverless computing is a growing cloud framework that removes the barriers of resource provision and scaling from the cloud users. Function-as-a-Service (FaaS) is a
way to deploy an application, as a set of functions, to serverless backends in the cloud.
The functions are usually short-lived and have unpredictable invocation patterns. A
typical cloud environment has multiple tenants coreside on a server. The combination
of the multitenancy and functionsâ€™ characterization leads to that a serverless platform
has to address the potential overheads of burstable invocations. This project studies the
architectural implications of serverless computing under a high multitenancy. We explicitly measure the throughput and hardware performance counters of a server while
the number of tenants varies. We find that the server suffers an approximately 40%
of throughput loss when the number of tenants exceeds the number of physical cores.
The characteristics of hardware performance counters show that the contention of data
demands on the memory subsystem is rapidly aggravated as the number of tenants increases. When two tenants coreside on the same physical core, the contention on the
instruction fetch may overtake the stalls in the memory subsystem. We also conform
that the interleaves short functions from multiple tenants are harmful to the localitypreserving microarchitectural structures. We open-source an automated profiling tool
in the vHive, which we developed for this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning Practical - Paraphrase Conditioning Model</title>
      <link>https://example.com/project/mlp/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/mlp/</guid>
      <description>&lt;p&gt;In this project, we studied the effectiveness of
length ratio conditioning on paraphrase genera-
tion. We constructed two datasets. One used
a pretrained NMT model to construct a new
paraphrasing dataset from WMT 2019 Europarl
German-English dataset, and the other was ex-
tracted from MSCOCO and QUORA question
pairs dataset. We proposed tagging and fine-
tuning methods on length ratio for condition-
ing paraphrase generation. Finally we evaluate
length-ratio conditioning performance of models
from semantic similarity and length change. The
major finding is that tagging had little to no effect
on conditioning tasks while having a better para-
phrase performance. In comparison, however,
fine-tuning is more effective in conditioning but
showed poor performance in paraphrasing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>System Design Project - Tadashi Robot</title>
      <link>https://example.com/project/sdp/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/sdp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Informatics Large Practical - Route Planning</title>
      <link>https://example.com/project/ilp/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/ilp/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://example.com/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
