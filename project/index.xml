<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Yuchen Niu</title>
    <link>https://example.com/project/</link>
      <atom:link href="https://example.com/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 06 May 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://example.com/media/icon_hue3a655598c6865a5273e9cfb01f02a1f_2400_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://example.com/project/</link>
    </image>
    
    <item>
      <title>Calibrating Uncertainty Estimates for Machine Learning Models</title>
      <link>https://example.com/project/iso/</link>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/iso/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;http://yingzhenli.net/home/en/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Yingzhen Li&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recent advances in machine learning have dramatically improved the ability of neural
networks to solve real-world problems. Machine learning methods are also more frequently
deployed in critical scenarios. This requires that machine learning models need to be both
accurate and reliable. So, calibrating a model to create a rigorous confidence set or estimates
that represent the actual correctness likelihood is essential. In this report, we review the
theoretical and practical concepts of uncertainty estimation and calibration. The history of
popular calibration models and their application are also covered, which will help understand
concepts more intuitively. We conduct experiments on the uncertainty estimation of neural
networks before and after applying various post-processing calibration methods. Empirical
results show that modern neural networks are often overconfident and poorly calibrated.
Temperature scaling is straightforward and surprisingly efficient at calibrating confidence for
classification models. Conformal prediction is a non-parametric distribution-free calibration
method for regression models. However, we notice that distribution shifts and biases can
easily influence the confidence interval for predictions from conformal inference. Ensembling
can be an implicit calibration method that can mitigate the overconfidence of neural networks
and provide stable predictions.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prompt Tuning for Condescending Detection</title>
      <link>https://example.com/project/icnlp/</link>
      <pubDate>Fri, 04 Mar 2022 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/icnlp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Performance Characterization of Serverless Computing</title>
      <link>https://example.com/project/ug_thesis/</link>
      <pubDate>Mon, 12 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/ug_thesis/</guid>
      <description>&lt;p&gt;Supervised by &lt;a href=&#34;https://homepages.inf.ed.ac.uk/bgrot/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Boris Grot&lt;/a&gt; and &lt;a href=&#34;https://homepages.inf.ed.ac.uk/s1373190/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dr Dmitrii Ustiugov&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Serverless computing is a growing cloud framework that removes the barriers of resource provision and scaling from the cloud users. Function-as-a-Service (FaaS) is a
way to deploy an application, as a set of functions, to serverless backends in the cloud.
The functions are usually short-lived and have unpredictable invocation patterns. A
typical cloud environment has multiple tenants coreside on a server. The combination
of the multitenancy and functionsâ€™ characterization leads to that a serverless platform
has to address the potential overheads of burstable invocations. This project studies the
architectural implications of serverless computing under a high multitenancy. We explicitly measure the throughput and hardware performance counters of a server while
the number of tenants varies. We find that the server suffers an approximately 40%
of throughput loss when the number of tenants exceeds the number of physical cores.
The characteristics of hardware performance counters show that the contention of data
demands on the memory subsystem is rapidly aggravated as the number of tenants increases. When two tenants coreside on the same physical core, the contention on the
instruction fetch may overtake the stalls in the memory subsystem. We also conform
that the interleaves short functions from multiple tenants are harmful to the localitypreserving microarchitectural structures. We open-source an automated profiling tool
in the vHive, which we developed for this project.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning Practical</title>
      <link>https://example.com/project/mlp/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/mlp/</guid>
      <description>&lt;p&gt;In this project, we studied the effectiveness of
length ratio conditioning on paraphrase genera-
tion. We constructed two datasets. One used
a pretrained NMT model to construct a new
paraphrasing dataset from WMT 2019 Europarl
German-English dataset, and the other was ex-
tracted from MSCOCO and QUORA question
pairs dataset. We proposed tagging and fine-
tuning methods on length ratio for condition-
ing paraphrase generation. Finally we evaluate
length-ratio conditioning performance of models
from semantic similarity and length change. The
major finding is that tagging had little to no effect
on conditioning tasks while having a better para-
phrase performance. In comparison, however,
fine-tuning is more effective in conditioning but
showed poor performance in paraphrasing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>System Design Project</title>
      <link>https://example.com/project/sdp/</link>
      <pubDate>Sun, 12 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/sdp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Informatics Large Practical</title>
      <link>https://example.com/project/ilp/</link>
      <pubDate>Fri, 12 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/ilp/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
